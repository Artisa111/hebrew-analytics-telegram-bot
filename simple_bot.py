# -*- coding: utf-8 -*-
"""
×‘×•×˜ ×¤×©×•×˜ ×œ×‘×“×™×§×” - Simple bot for testing with advanced PDF generation
"""

# Initialize logging before other imports
from logging_config import setup_logging
logger = setup_logging()

import os
import pandas as pd
import numpy as np
import tempfile
import shutil
import matplotlib
# Enforce headless backend before importing pyplot
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from telegram import Update, ReplyKeyboardMarkup, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import Application, CommandHandler, MessageHandler, CallbackQueryHandler, ContextTypes, filters
from telegram.constants import ParseMode
from sklearn.cluster import KMeans
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, r2_score
from pdf_report import generate_complete_data_report

# Setup logging
logger.info("Simple Hebrew Bot starting with advanced PDF generation")

# ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° matplotlib Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¸ Ğ¸Ğ²Ñ€Ğ¸Ñ‚Ğ°
plt.rcParams['font.family'] = ['DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

class SimpleHebrewBot:
    def __init__(self, bot_token: str):
        self.application = Application.builder().token(bot_token).job_queue(None).persistence(None).build()
        self.user_data = {}  # ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
        self.setup_handlers()
    
    def setup_handlers(self):
        """×”×’×“×¨×ª handlers ×¤×©×•×˜×™×"""
        self.application.add_handler(CommandHandler("start", self.start_command))
        self.application.add_handler(CommandHandler("help", self.help_command))
        self.application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, self.handle_text))
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²
        self.application.add_handler(MessageHandler(filters.Document.ALL, self.handle_document))
    
    async def start_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×¤×§×•×“×ª start ×¤×©×•×˜×”"""
        user = update.effective_user
        user_id = user.id
        
        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
        self.user_data[user_id] = {
            'data': None,
            'file_name': None,
            'analysis_done': False
        }
        
        welcome_text = f"×‘×¨×•×š ×”×‘× {user.first_name}! ğŸ‰\n\n×× ×™ ×‘×•×˜ × ×™×ª×•×— × ×ª×•× ×™× ×‘×¢×‘×¨×™×ª.\n\nğŸ“ ×©×œ×— ×œ×™ ×§×•×‘×¥ CSV ××• Excel ×›×“×™ ×œ×”×ª×—×™×œ!"
        
        keyboard = [
            ['ğŸ“Š × ×™×ª×•×— × ×ª×•× ×™×'],
            ['ğŸ“ˆ ×ª×¨×©×™××™×'],
            ['ğŸ’¡ ×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª'],
            ['ğŸ“„ ×“×•×— PDF', 'ğŸ“Š ×“×•×— PDF ××ª×§×“×'],  # ×©×ª×™ ××¤×©×¨×•×™×•×ª PDF
            ['ğŸ“ ×”×¢×œ××ª ×§×•×‘×¥'],
            ['â“ ×¢×–×¨×”']
        ]
        reply_markup = ReplyKeyboardMarkup(keyboard, resize_keyboard=True)
        
        await update.message.reply_text(welcome_text, reply_markup=reply_markup)
    
    async def help_command(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×¤×§×•×“×ª help ×¤×©×•×˜×”"""
        help_text = """
ğŸ“š **×¢×–×¨×” - ×‘×•×˜ × ×™×ª×•×— × ×ª×•× ×™× ×‘×¢×‘×¨×™×ª**

**×¤×§×•×“×•×ª ×–××™× ×•×ª:**
/start - ×”×ª×—×œ×ª ×©×™××•×© ×‘×‘×•×˜
/help - ×”×¦×’×ª ×¢×–×¨×” ×–×•

**×™×›×•×œ×•×ª ×”×‘×•×˜:**
â€¢ ğŸ“ ×”×¢×œ××ª ×§×‘×¦×™ CSV ×•-Excel
â€¢ ğŸ“Š × ×™×ª×•×— × ×ª×•× ×™× ××§×™×£
â€¢ ğŸ“ˆ ×™×¦×™×¨×ª ×ª×¨×©×™××™× ××§×¦×•×¢×™×™×
â€¢ ğŸ’¡ ×ª×•×‘× ×•×ª ××•×˜×•××˜×™×•×ª ×•×”××œ×¦×•×ª
â€¢ ğŸ” ×–×™×”×•×™ ×“×¤×•×¡×™× ×•×× ×•××œ×™×•×ª
â€¢ ğŸ“„ ×“×•×—×•×ª PDF ×‘×¢×‘×¨×™×ª (×¨×’×™×œ ×•××ª×§×“×)

**××™×š ×œ×”×©×ª××©:**
1. ×©×œ×— ×œ×™ ×§×•×‘×¥ CSV ××• Excel
2. ×‘×—×¨ "× ×™×ª×•×— × ×ª×•× ×™×" ×œ× ×™×ª×•×— ××§×™×£
3. ×‘×—×¨ "×ª×¨×©×™××™×" ×œ×™×¦×™×¨×ª ×’×¨×¤×™×
4. ×‘×—×¨ "×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª" ×œ×§×‘×œ×ª ×ª×•×‘× ×•×ª
5. ×‘×—×¨ "×“×•×— PDF ××ª×§×“×" ×œ×“×•×— ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª

**×“×•×— PDF ××ª×§×“× ××›×™×œ:**
â€¢ × ×™×ª×•×— ××¢××™×§ ×©×œ ×”× ×ª×•× ×™×
â€¢ ×’×¨×¤×™× ××§×¦×•×¢×™×™×
â€¢ ×ª×•×‘× ×•×ª ×•××¡×§× ×•×ª
â€¢ ×”××œ×¦×•×ª ××•×ª×××•×ª ××™×©×™×ª
â€¢ ×¢×™×¦×•×‘ ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª ××™××™×Ÿ ×œ×©×××œ

**×œ×©××œ×•×ª × ×•×¡×¤×•×ª, ×¤× ×” ×œ××¤×ª×— ×”×‘×•×˜.**
        """
        await update.message.reply_text(help_text, parse_mode=ParseMode.MARKDOWN)
    
    def has_data(self, user_id: int) -> bool:
        """ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµÑ‚, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ñƒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"""
        if user_id not in self.user_data:
            return False
        data = self.user_data[user_id].get('data')
        return data is not None and isinstance(data, pd.DataFrame) and not data.empty
    
    async def handle_document(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×§×‘×¦×™× ×©×”×•×¢×œ×•"""
        user_id = update.effective_user.id
        document = update.message.document
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        if user_id not in self.user_data:
            self.user_data[user_id] = {'data': None, 'file_name': None, 'analysis_done': False}
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ñ„Ğ°Ğ¹Ğ»Ğ°
        file_name = document.file_name
        file_extension = os.path.splitext(file_name)[1].lower()
        
        supported_formats = ['.csv', '.xlsx', '.xls']
        if file_extension not in supported_formats:
            await update.message.reply_text(
                f"âŒ ×¡×•×’ ×§×•×‘×¥ ×œ× × ×ª××š: {file_extension}\n\n×”×§×‘×¦×™× ×”× ×ª××›×™×: {', '.join(supported_formats)}"
            )
            return
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ Ñ€Ğ°Ğ·Ğ¼ĞµÑ€ Ñ„Ğ°Ğ¹Ğ»Ğ° (Ğ¼Ğ°ĞºÑĞ¸Ğ¼ÑƒĞ¼ 50MB)
        max_size = 50 * 1024 * 1024  # 50MB
        if document.file_size > max_size:
            await update.message.reply_text(
                f"âŒ ×”×§×•×‘×¥ ×’×“×•×œ ××“×™: {document.file_size // (1024*1024)}MB\n\n×”×’×•×“×œ ×”××§×¡×™××œ×™: 50MB"
            )
            return
        
        await update.message.reply_text("ğŸ“ ×§×•×‘×¥ ×”×ª×§×‘×œ! ××¢×‘×“...")
        
        try:
            # Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
            file = await context.bot.get_file(document.file_id)
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ
            temp_dir = tempfile.mkdtemp()
            file_path = os.path.join(temp_dir, file_name)
            
            # Ğ¡ĞºĞ°Ñ‡Ğ¸Ğ²Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
            await file.download_to_drive(file_path)
            
            # Ğ§Ğ¸Ñ‚Ğ°ĞµĞ¼ Ñ„Ğ°Ğ¹Ğ»
            df = await self.read_data_file(file_path, file_extension)
            
            if df is not None and isinstance(df, pd.DataFrame) and not df.empty:
                # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
                self.user_data[user_id].update({
                    'data': df,
                    'file_name': file_name,
                    'analysis_done': False
                })
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğµ
                rows, cols = df.shape
                await update.message.reply_text(
                    f"âœ… ×”×§×•×‘×¥ ×¢×•×‘×“ ×‘×”×¦×œ×—×”!\n\n"
                    f"ğŸ“Š ××™×“×¢ ×¢×œ ×”×§×•×‘×¥:\n"
                    f"â€¢ ×©×: {file_name}\n"
                    f"â€¢ ×©×•×¨×•×ª: {rows:,}\n"
                    f"â€¢ ×¢××•×“×•×ª: {cols}\n"
                    f"â€¢ ×’×•×“×œ: {document.file_size // 1024}KB\n\n"
                    f"×¢×›×©×™×• ××ª×” ×™×›×•×œ ×œ×‘×—×•×¨:\n"
                    f"â€¢ '× ×™×ª×•×— × ×ª×•× ×™×' - ×œ× ×™×ª×•×— ××¤×•×¨×˜\n"
                    f"â€¢ '×ª×¨×©×™××™×' - ×œ×™×¦×™×¨×ª ×’×¨×¤×™×\n"
                    f"â€¢ '×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª' - ×œ×§×‘×œ×ª ×ª×•×‘× ×•×ª\n"
                    f"â€¢ '×“×•×— PDF ××ª×§×“×' - ×œ×“×•×— ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª! ğŸ¯"
                )
                
                # ĞŸĞ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ñ€Ğ¾Ğº (ĞºĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¾)
                preview = df.head(2).to_string(index=False, max_cols=3)
                if len(preview) > 1000:
                    preview = preview[:1000] + "..."
                await update.message.reply_text(f"ğŸ‘€ ×ª×¦×•×’×” ××§×“×™××”:\n```\n{preview}\n```", parse_mode=ParseMode.MARKDOWN)
                
            else:
                await update.message.reply_text("âŒ ×©×’×™××” ×‘×§×¨×™××ª ×”×§×•×‘×¥. ×× × ×•×“× ×©×”×§×•×‘×¥ ×ª×§×™×Ÿ ×•×œ× ×¨×™×§.")
            
        except Exception as e:
            logger.error(f"Error handling document: {e}")
            await update.message.reply_text("âŒ ×©×’×™××” ×‘×¢×™×‘×•×“ ×”×§×•×‘×¥. ×× × × ×¡×” ×©×•×‘.")
        
        finally:
            # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½ÑƒÑ Ğ¿Ğ°Ğ¿ĞºÑƒ
            if 'temp_dir' in locals():
                shutil.rmtree(temp_dir, ignore_errors=True)
    
    async def read_data_file(self, file_path: str, file_extension: str):
        """×§×¨×™××ª ×§×•×‘×¥ × ×ª×•× ×™×"""
        try:
            if file_extension == '.csv':
                # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ€Ğ°Ğ·Ğ½Ñ‹Ğµ ĞºĞ¾Ğ´Ğ¸Ñ€Ğ¾Ğ²ĞºĞ¸
                encodings = ['utf-8', 'latin-1', 'cp1255', 'iso-8859-8']
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file_path, encoding=encoding)
                        if isinstance(df, pd.DataFrame) and not df.empty:
                            return df
                    except UnicodeDecodeError:
                        continue
                return None
            
            elif file_extension in ['.xlsx', '.xls']:
                df = pd.read_excel(file_path)
                if isinstance(df, pd.DataFrame) and not df.empty:
                    return df
            
            return None
            
        except Exception as e:
            logger.error(f"Error reading file {file_path}: {e}")
            return None
    
    async def handle_text(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×”×•×“×¢×•×ª ×˜×§×¡×˜ ×¤×©×•×˜×•×ª"""
        user_id = update.effective_user.id
        text = update.message.text
        
        # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, ĞµÑÑ‚ÑŒ Ğ»Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ² Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
        if user_id not in self.user_data:
            self.user_data[user_id] = {'data': None, 'file_name': None, 'analysis_done': False}
        
        if text == 'ğŸ“Š × ×™×ª×•×— × ×ª×•× ×™×':
            await self.handle_analyze_data(update, context)
        
        elif text == 'ğŸ“ˆ ×ª×¨×©×™××™×':
            await self.handle_charts(update, context)
        
        elif text == 'ğŸ’¡ ×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª':
            await self.handle_insights(update, context)

        elif text == 'ğŸ“„ ×“×•×— PDF':
            # ×“×•×— PDF ×¨×’×™×œ (×™×©×Ÿ)
            if not self.has_data(user_id):
                await update.message.reply_text("âŒ ××™×Ÿ × ×ª×•× ×™× ×œ×“×•×—! ×©×œ×— ×§×•×‘×¥ ×ª×—×™×œ×”.")
                return
            
            await update.message.reply_text("ğŸ–¨ï¸ ×™×•×¦×¨ ×“×•×— PDF ×¨×’×™×œ ×‘×¢×‘×¨×™×ªâ€¦")
            
            try:
                df = self.user_data[user_id]['data']
                numeric_cols = df.select_dtypes(include=[np.number]).columns
                analysis_results = {
                    'basic_info': {
                        'shape': df.shape,
                        'memory_usage': df.memory_usage(deep=True).sum(),
                        'null_counts': df.isnull().sum().to_dict(),
                    }
                }
                # quick top correlations for report
                if len(numeric_cols) > 1:
                    analysis_results['correlation_matrix'] = df[numeric_cols].corr()
                
                # reuse last charts if exist; otherwise, build minimal hist for first numeric
                chart_dir = os.path.join(os.getcwd(), 'temp_charts')
                chart_files = []
                if os.path.isdir(chart_dir):
                    for name in os.listdir(chart_dir):
                        if name.lower().endswith('.png'):
                            chart_files.append(os.path.join(chart_dir, name))
                
                if not chart_files and len(numeric_cols) > 0:
                    import matplotlib.pyplot as plt
                    path = os.path.join(chart_dir, 'pdf_quick_hist.png')
                    os.makedirs(chart_dir, exist_ok=True)
                    plt.hist(df[numeric_cols[0]].dropna(), bins=25)
                    plt.title(str(numeric_cols[0]))
                    plt.savefig(path, dpi=200)
                    plt.close()
                    chart_files.append(path)

                out_path = os.path.join(os.getcwd(), 'analysis_report.pdf')
                pdf_path = generate_complete_data_report(df, out_path, include_charts=True)
                
                if pdf_path and os.path.exists(pdf_path):
                    with open(pdf_path, 'rb') as f:
                        await context.bot.send_document(
                            chat_id=update.effective_chat.id, 
                            document=f, 
                            filename=os.path.basename(pdf_path), 
                            caption='×“×•×— PDF ×¨×’×™×œ ×”×•×›×Ÿ ×‘×”×¦×œ×—×”! ğŸ“„'
                        )
                else:
                    await update.message.reply_text('âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×“×•×— ×”×¨×’×™×œ')
                    
            except Exception as e:
                logger.error(f"Error sending regular PDF: {e}")
                await update.message.reply_text('âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×“×•×— ×”×¨×’×™×œ')

        elif text == 'ğŸ“Š ×“×•×— PDF ××ª×§×“×':
            # ×“×•×— PDF ××ª×§×“× (×—×“×© ×•××©×•×¤×¨)
            if not self.has_data(user_id):
                await update.message.reply_text("âŒ ××™×Ÿ × ×ª×•× ×™× ×œ×“×•×— ××ª×§×“×! ×©×œ×— ×§×•×‘×¥ ×ª×—×™×œ×”.")
                return
            
            await update.message.reply_text("ğŸš€ ×™×•×¦×¨ ×“×•×— PDF ××ª×§×“× ×‘×¢×‘×¨×™×ª ×¢× × ×™×ª×•×— ××§×™×£, ×’×¨×¤×™× ××§×¦×•×¢×™×™× ×•×ª×•×›×Ÿ ××•×‘×˜×— ×‘×›×œ ×¡×¢×™×£â€¦")
            
            try:
                df = self.user_data[user_id]['data']
                file_name = self.user_data[user_id]['file_name']
                
                # ×™×¦×™×¨×ª ×©× ×§×•×‘×¥ ××•×ª××
                base_name = os.path.splitext(file_name)[0] if file_name else "× ×ª×•× ×™×"
                out_path = os.path.join(os.getcwd(), f'×“×•×—_××ª×§×“×_{base_name}.pdf')
                
                # ×©×™××•×© ×‘×¤×•× ×§×¦×™×” ×”×—×“×©×” ×•×”××©×•×¤×¨×ª ×¢× ×ª×•×›×Ÿ ××•×‘×˜×—
                pdf_path = generate_complete_data_report(df, out_path, include_charts=True)
                
                if pdf_path and os.path.exists(pdf_path):
                    with open(pdf_path, 'rb') as f:
                        await context.bot.send_document(
                            chat_id=update.effective_chat.id, 
                            document=f, 
                            filename=os.path.basename(pdf_path), 
                            caption='ğŸ‰ ×“×•×— PDF ××ª×§×“× ×¢× ×ª×•×›×Ÿ ××•×‘×˜×— ×”×•×›×Ÿ ×‘×”×¦×œ×—×”!\n\n'
                                   'âœ¨ ×”×“×•×— ×›×•×œ×œ:\n'
                                   'â€¢ × ×™×ª×•×— ××¢××™×§ ×©×œ ×”× ×ª×•× ×™× ×¢× ×ª×•×›×Ÿ ××•×‘×˜×—\n'
                                   'â€¢ ×’×¨×¤×™× ××§×¦×•×¢×™×™× ×•×•×™×–×•××œ×™×–×¦×™×•×ª ××™×›×•×ª×™×•×ª\n'
                                   'â€¢ ×ª×•×‘× ×•×ª ×•××¡×§× ×•×ª ××•×˜×•××˜×™×•×ª ××¤×•×¨×˜×•×ª\n'
                                   'â€¢ ×”××œ×¦×•×ª ××•×ª×××•×ª ××™×©×™×ª ×¢× ×”×¡×‘×¨×™×\n'
                                   'â€¢ × ×™×ª×•×— ×¢×¨×›×™× ×—×¨×™×’×™× ×•×§×•×¨×œ×¦×™×•×ª\n'
                                   'â€¢ ×¡×™×›×•× ×¡×˜×˜×™×¡×˜×™ ××§×™×£\n'
                                   'â€¢ ×¢×™×¦×•×‘ ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª ××™××™×Ÿ ×œ×©×××œ\n'
                                   'â€¢ ×ª×•×›×Ÿ ××•×‘×˜×— ×‘×›×œ ×¡×¢×™×£ - ××£ ×¡×¢×™×£ ×œ× ×™×™×©××¨ ×¨×™×§!'
                        )
                    
                    # ×”×•×“×¢×ª ××¢×§×‘
                    await update.message.reply_text(
                        "ğŸ¯ **×“×•×— PDF ××ª×§×“× ×¢× ×ª×•×›×Ÿ ××•×‘×˜×— × ×•×¦×¨ ×‘×”×¦×œ×—×”!**\n\n"
                        "ğŸ”¥ **×—×™×“×•×©×™× ×‘×“×•×— ×”×—×“×©:**\n"
                        "âœ… ×ª×•×›×Ÿ ××•×‘×˜×— ×‘×›×œ ×¡×¢×™×£ - ××£ ×¡×¢×™×£ ×œ× × ×©××¨ ×¨×™×§\n"
                        "ğŸ“Š × ×™×ª×•×— ×¡×˜×˜×™×¡×˜×™ ××œ× ×¢× ×”×¡×‘×¨×™× ××¤×•×¨×˜×™×\n"
                        "ğŸ“ˆ ×’×¨×¤×™× ××§×¦×•×¢×™×™× ×¢× ×ª×™××•×¨×™× ×‘×¢×‘×¨×™×ª\n"
                        "ğŸ” ×–×™×”×•×™ ×§×•×¨×œ×¦×™×•×ª ×•×—×¨×™×’×™× ×¢× ×”××œ×¦×•×ª\n"
                        "ğŸ’¡ ×ª×•×‘× ×•×ª ×¢×¡×§×™×•×ª ××•×ª×××•×ª ××™×©×™×ª\n"
                        "ğŸ¨ ×¢×™×¦×•×‘ ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª ××™××™×Ÿ ×œ×©×××œ\n"
                        "ğŸ›¡ï¸ ×¢××™×“×•×ª ××•×œ × ×ª×•× ×™× ×‘×¢×™×™×ª×™×™×\n\n"
                        "ğŸš€ ×–×”×• ×“×•×— ××ª×§×“× ×•××§×¦×•×¢×™ ×©××‘×˜×™×— ×ª×•×›×Ÿ ××™×›×•×ª×™ ×‘×›×œ ××§×¨×”!",
                        parse_mode=ParseMode.MARKDOWN
                    )
                    
                else:
                    await update.message.reply_text('âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×“×•×— ×”××ª×§×“×')
                    
            except Exception as e:
                logger.error(f"Error sending advanced PDF: {e}")
                await update.message.reply_text('âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×“×•×— ×”××ª×§×“×')
        
        elif text == 'ğŸ“ ×”×¢×œ××ª ×§×•×‘×¥':
            await update.message.reply_text(
                "ğŸ“ **×”×¢×œ××ª ×§×‘×¦×™×**\n\n"
                "×©×œ×— ×œ×™ ×§×•×‘×¥ CSV ××• Excel ×›×“×™ ×œ×”×ª×—×™×œ!\n\n"
                "**×§×‘×¦×™× × ×ª××›×™×:**\n"
                "â€¢ CSV (.csv)\n"
                "â€¢ Excel (.xlsx, .xls)\n\n"
                "**××’×‘×œ×•×ª:**\n"
                "â€¢ ×’×•×“×œ ××§×¡×™××œ×™: 50MB\n"
                "â€¢ ××¡×¤×¨ ×©×•×¨×•×ª: ×œ×œ× ×”×’×‘×œ×”\n"
                "â€¢ ××¡×¤×¨ ×¢××•×“×•×ª: ×œ×œ× ×”×’×‘×œ×”\n\n"
                "**×˜×™×¤×™×:**\n"
                "â€¢ ×•×•×“× ×©×”×§×•×‘×¥ ××›×™×œ ×›×•×ª×¨×•×ª ×¢××•×“×•×ª\n"
                "â€¢ ×‘×“×•×§ ×©××™×Ÿ ×©×•×¨×•×ª ×¨×™×§×•×ª ×‘×ª×—×™×œ×ª ×”×§×•×‘×¥\n"
                "â€¢ ×”×©×ª××© ×‘×§×™×“×•×“ UTF-8 ×œ×ª××™×›×” ×‘×¢×‘×¨×™×ª",
                parse_mode=ParseMode.MARKDOWN
            )
        
        elif text == 'â“ ×¢×–×¨×”':
            await self.help_command(update, context)
        
        else:
            await update.message.reply_text(
                "×œ× ×”×‘× ×ª×™ ××ª ×”×”×•×“×¢×” ×©×œ×š. ğŸ¤”\n\n"
                "×× × ×”×©×ª××© ×‘×›×¤×ª×•×¨×™× ×©×œ××˜×” ××• ×©×œ×— /help ×œ×¢×–×¨×” ××¤×•×¨×˜×ª.\n\n"
                "ğŸ’¡ ×× ×™×© ×œ×š ×§×•×‘×¥ × ×ª×•× ×™× - ×¤×©×•×˜ ×©×œ×— ××•×ª×• ×œ×™!"
            )
    
    async def handle_analyze_data(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘× ×™×ª×•×— × ×ª×•× ×™×"""
        user_id = update.effective_user.id
        
        if not self.has_data(user_id):
            await update.message.reply_text(
                "âŒ ××™×Ÿ × ×ª×•× ×™× ×œ× ×™×ª×•×—!\n\n"
                "×× × ×©×œ×— ×œ×™ ×§×•×‘×¥ CSV ××• Excel ×ª×—×™×œ×”."
            )
            return
        
        await update.message.reply_text("ğŸ” ×× ×ª×— × ×ª×•× ×™×...")
        
        try:
            df = self.user_data[user_id]['data']
            
            # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·
            analysis_text = f"ğŸ” **× ×™×ª×•×— ××¤×•×¨×˜: {self.user_data[user_id]['file_name']}**\n\n"
            
            # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ
            rows, cols = df.shape
            analysis_text += f"ğŸ“Š **××™×“×¢ ×‘×¡×™×¡×™:**\n"
            analysis_text += f"â€¢ ××¡×¤×¨ ×©×•×¨×•×ª: {rows:,}\n"
            analysis_text += f"â€¢ ××¡×¤×¨ ×¢××•×“×•×ª: {cols}\n"
            analysis_text += f"â€¢ ×©× ×§×•×‘×¥: {self.user_data[user_id]['file_name']}\n\n"
            
            # Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ°Ñ…
            analysis_text += f"**×¢××•×“×•×ª ×•×˜×™×¤×•×¡×™ × ×ª×•× ×™×:**\n"
            for i, col in enumerate(df.columns, 1):
                col_type = str(df[col].dtype)
                null_count = df[col].isnull().sum()
                unique_count = df[col].nunique()
                analysis_text += f"{i}. {col} ({col_type})"
                if null_count > 0:
                    null_percentage = (null_count / len(df)) * 100
                    analysis_text += f" - {null_count} ×¢×¨×›×™× ×—×¡×¨×™× ({null_percentage:.1f}%)"
                analysis_text += f" - {unique_count} ×¢×¨×›×™× ×™×™×—×•×“×™×™×\n"
            
            # Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ğ°Ñ ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ´Ğ»Ñ Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ… ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                analysis_text += f"\nğŸ“Š **×¡×˜×˜×™×¡×˜×™×§×” ××¡×¤×¨×™×ª ××¤×•×¨×˜×ª:**\n"
                for col in numeric_cols:
                    stats = df[col].describe()
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    analysis_text += f"\n**{col}:**\n"
                    analysis_text += f"â€¢ ×××•×¦×¢: {stats['mean']:.2f}\n"
                    analysis_text += f"â€¢ ×—×¦×™×•×Ÿ: {stats['50%']:.2f}\n"
                    analysis_text += f"â€¢ ×¡×˜×™×™×ª ×ª×§×Ÿ: {stats['std']:.2f}\n"
                    analysis_text += f"â€¢ ××™× ×™××•×: {stats['min']:.2f}\n"
                    analysis_text += f"â€¢ ××§×¡×™××•×: {stats['max']:.2f}\n"
                    analysis_text += f"â€¢ Q1: {Q1:.2f}\n"
                    analysis_text += f"â€¢ Q3: {Q3:.2f}\n"
            
            # ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… ĞºĞ¾Ğ»Ğ¾Ğ½Ğ¾Ğº
            categorical_cols = df.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                analysis_text += f"\n**× ×™×ª×•×— ×§×˜×’×•×¨×™×•×ª:**\n"
                for col in categorical_cols[:3]:  # Ğ¢Ğ¾Ğ»ÑŒĞºĞ¾ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ 3
                    value_counts = df[col].value_counts()
                    most_common = value_counts.head(3)
                    analysis_text += f"â€¢ {col}:\n"
                    for val, count in most_common.items():
                        percentage = (count / len(df)) * 100
                        analysis_text += f"  - {val}: {count} ({percentage:.1f}%)\n"
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
            duplicates = df.duplicated().sum()
            if duplicates > 0:
                analysis_text += f"\n**âš ï¸ ××–×”×¨×•×ª:**\n"
                analysis_text += f"â€¢ × ××¦××• {duplicates} ×©×•×¨×•×ª ×›×¤×•×œ×•×ª\n"
            
            # ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            total_cells = len(df) * len(df.columns)
            total_nulls = df.isnull().sum().sum()
            if total_nulls > 0:
                null_percentage = (total_nulls / total_cells) * 100
                analysis_text += f"\n**ğŸ” ××™×›×•×ª × ×ª×•× ×™×:**\n"
                analysis_text += f"â€¢ ×¢×¨×›×™× ×—×¡×¨×™×: {total_nulls:,} ({null_percentage:.1f}% ××”× ×ª×•× ×™×)\n"
                if null_percentage > 20:
                    analysis_text += f"  - âš ï¸ ××—×•×– ×’×‘×•×” ×©×œ ×¢×¨×›×™× ×—×¡×¨×™× - ×©×§×•×œ ×œ×‘×“×•×§ ××ª ××§×•×¨ ×”× ×ª×•× ×™×\n"
                elif null_percentage > 10:
                    analysis_text += f"  - âš ï¸ ××—×•×– ×‘×™× ×•× ×™ ×©×œ ×¢×¨×›×™× ×—×¡×¨×™× - ×™×™×ª×›×Ÿ ×©×™×™×“×¨×© ×˜×™×¤×•×œ\n"
                else:
                    analysis_text += f"  - âœ… ××—×•×– × ××•×š ×©×œ ×¢×¨×›×™× ×—×¡×¨×™× - × ×ª×•× ×™× ×‘××™×›×•×ª ×˜×•×‘×”\n"
            
            self.user_data[user_id]['analysis_done'] = True
            
            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
            if len(analysis_text) > 4000:
                parts = [analysis_text[i:i+4000] for i in range(0, len(analysis_text), 4000)]
                for i, part in enumerate(parts):
                    if i == 0:
                        await update.message.reply_text(part, parse_mode=ParseMode.MARKDOWN)
                    else:
                        await update.message.reply_text(f"ğŸ“Š ×”××©×š ×”× ×™×ª×•×— (×—×œ×§ {i+1}):\n\n{part}", parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(analysis_text, parse_mode=ParseMode.MARKDOWN)
            
            await update.message.reply_text(
                "âœ… ×”× ×™×ª×•×— ×”×•×©×œ×!\n\n"
                "**××” ×¢×›×©×™×•?**\n"
                "ğŸ“ˆ '×ª×¨×©×™××™×' - ×œ×™×¦×™×¨×ª ×’×¨×¤×™× ××§×¦×•×¢×™×™×\n"
                "ğŸ’¡ '×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª' - ×œ×§×‘×œ×ª ×ª×•×‘× ×•×ª ××ª×§×“××•×ª\n"
                "ğŸ“Š '×“×•×— PDF ××ª×§×“×' - ×œ×“×•×— ××§×¦×•×¢×™ ××œ×! ğŸ¯",
                parse_mode=ParseMode.MARKDOWN
            )
            
        except Exception as e:
            logger.error(f"Error analyzing data: {e}")
            await update.message.reply_text("âŒ ×©×’×™××” ×‘× ×™×ª×•×— ×”× ×ª×•× ×™×")
    
    async def handle_charts(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×ª×¨×©×™××™× - ×™×¦×™×¨×ª ×ª×¨×©×™××™× ××§×¦×•×¢×™×™× ×•××ª×§×“××™×"""
        user_id = update.effective_user.id
        
        if not self.has_data(user_id):
            await update.message.reply_text(
                "âŒ ××™×Ÿ × ×ª×•× ×™× ×œ×ª×¨×©×™××™×!\n\n"
                "×× × ×©×œ×— ×œ×™ ×§×•×‘×¥ CSV ××• Excel ×ª×—×™×œ×”."
            )
            return
        
        await update.message.reply_text("ğŸ“ˆ ×™×•×¦×¨ ×ª×¨×©×™××™× ××§×¦×•×¢×™×™×...")
        
        try:
            df = self.user_data[user_id]['data']
            chart_files = []
            chart_insights = {}
            chart_next_steps = {}
            
            # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ğ°Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ²
            temp_charts_dir = tempfile.mkdtemp()
            
            # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° ÑÑ‚Ğ¸Ğ»Ñ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ñ„ĞµÑÑĞ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¾Ğ²
            plt.style.use('seaborn-v0_8')
            sns.set_palette("husl")
            
            # 1. Ğ“Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ñ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ½Ñ‹Ğ¼ Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½Ğ¾Ğ¼
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 0:
                for col in numeric_cols[:3]:  # ĞŸĞµÑ€Ğ²Ñ‹Ğµ 3 Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸
                    plt.figure(figsize=(12, 8))
                    
                    # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¿Ğ¾Ğ´Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸
                    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))
                    
                    # Ğ“Ğ¸ÑÑ‚Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°
                    ax1.hist(df[col].dropna(), bins=30, alpha=0.7, color='skyblue', 
                            edgecolor='navy', linewidth=1.2)
                    ax1.set_title(f'×”×™×¡×˜×•×’×¨××” ×©×œ {col}', fontsize=16, fontweight='bold', pad=20)
                    ax1.set_xlabel(col, fontsize=12, fontweight='bold')
                    ax1.set_ylabel('×ª×“×™×¨×•×ª', fontsize=12, fontweight='bold')
                    ax1.grid(True, alpha=0.3, linestyle='--')
                    ax1.axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, 
                               label=f'×××•×¦×¢: {df[col].mean():.2f}')
                    ax1.axvline(df[col].median(), color='green', linestyle='--', linewidth=2, 
                               label=f'×—×¦×™×•×Ÿ: {df[col].median():.2f}')
                    ax1.legend(fontsize=10)
                    
                    # Box plot
                    ax2.boxplot(df[col].dropna(), patch_artist=True, 
                               boxprops=dict(facecolor='lightblue', alpha=0.7),
                               medianprops=dict(color='red', linewidth=2))
                    ax2.set_title(f'Box Plot ×©×œ {col}', fontsize=14, fontweight='bold')
                    ax2.set_ylabel(col, fontsize=12, fontweight='bold')
                    ax2.grid(True, alpha=0.3, linestyle='--')
                    
                    plt.tight_layout()
                    chart_path = os.path.join(temp_charts_dir, f'histogram_box_{col}.png')
                    plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
                    plt.close()
                    chart_files.append(chart_path)

                    series = df[col].dropna()
                    if not series.empty:
                        mean_v = series.mean()
                        median_v = series.median()
                        std_v = series.std()
                        skew_v = series.skew()
                        q1 = series.quantile(0.25)
                        q3 = series.quantile(0.75)
                        iqr = q3 - q1
                        lower = q1 - 1.5 * iqr
                        upper = q3 + 1.5 * iqr
                        outliers = ((series < lower) | (series > upper)).sum()
                        out_pct = (outliers / len(series)) * 100.0
                        chart_insights[chart_path] = f"{col}: ×××•×¦×¢ {mean_v:.2f}, ×—×¦×™×•×Ÿ {median_v:.2f}, ×¡×˜×™×™×ª ×ª×§×Ÿ {std_v:.2f}, ×”×˜×™×” {skew_v:.2f}. ×—×¨×™×’×™×: {out_pct:.1f}%"
                        chart_next_steps[chart_path] = (
                            "××” ×”×œ××”:\n"
                            "â€¢ ×‘×“×™×§×ª ×—×¨×™×’×™× ×•×”×©×¤×¢×ª× ×¢×œ ×”××•×“×œ×™×\n"
                            "â€¢ ×× |×”×˜×™×”| ×’×‘×•×”×” â€” ×©×§×œ×• ×˜×¨× ×¡×¤×•×¨××¦×™×™×ª Log/Box-Cox\n"
                            "â€¢ ×”×©×•×•××ª ×”×”×ª×¤×œ×’×•×ª ×‘×™×Ÿ ×§×‘×•×¦×•×ª (A/B, ×¡×’×× ×˜×™×)"
                        )
            
            # 2. ĞšĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¼Ğ°Ñ‚Ñ€Ğ¸Ñ†Ğ°
            if len(numeric_cols) > 1:
                plt.figure(figsize=(12, 10))
                correlation_matrix = df[numeric_cols].corr()
                
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ Ğ¼Ğ°ÑĞºÑƒ Ğ´Ğ»Ñ Ğ²ĞµÑ€Ñ…Ğ½ĞµĞ³Ğ¾ Ñ‚Ñ€ĞµÑƒĞ³Ğ¾Ğ»ÑŒĞ½Ğ¸ĞºĞ°
                mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))
                
                # Ğ¡Ğ¾Ğ·Ğ´Ğ°ĞµĞ¼ heatmap
                sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlBu_r', 
                           center=0, square=True, linewidths=0.5, cbar_kws={"shrink": 0.8},
                           fmt='.3f', annot_kws={'size': 10, 'weight': 'bold'})
                
                plt.title('××˜×¨×™×¦×ª ×§×•×¨×œ×¦×™×” - Correlation Matrix', fontsize=16, fontweight='bold', pad=20)
                plt.tight_layout()
                
                chart_path = os.path.join(temp_charts_dir, 'correlation_matrix.png')
                plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
                plt.close()
                chart_files.append(chart_path)

                # Insights
                pairs = []
                cols_list = list(numeric_cols)
                for i in range(len(cols_list)):
                    for j in range(i+1, len(cols_list)):
                        val = correlation_matrix.loc[cols_list[i], cols_list[j]]
                        if not pd.isna(val):
                            pairs.append((cols_list[i], cols_list[j], float(val)))
                pairs.sort(key=lambda x: abs(x[2]), reverse=True)
                top_pairs = ', '.join([f"{a}â†”{b} ({c:.2f})" for a, b, c in pairs[:3]]) if pairs else "××™×Ÿ ×§×©×¨×™× ×—×–×§×™×"
                chart_insights[chart_path] = f"×–×•×’×•×ª ×§×•×¨×œ×¦×™×” ×‘×•×œ×˜×™×: {top_pairs}"
                chart_next_steps[chart_path] = (
                    "××” ×”×œ××”:\nâ€¢ ×‘×“×™×§×ª ×¨×’×¨×¡×™×” ×œ×–×•×’×•×ª ×—×–×§×™×\nâ€¢ ×˜×™×¤×•×œ ×‘××•×œ×˜×™×§×•×œ×™× ××¨×™×•×ª ×œ×¤× ×™ ML"
                )
            
            # 3. Ğ¡Ñ‚Ğ¾Ğ»Ğ±Ñ‡Ğ°Ñ‚Ñ‹Ğµ Ğ´Ğ¸Ğ°Ğ³Ñ€Ğ°Ğ¼Ğ¼Ñ‹ Ğ´Ğ»Ñ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            categorical_cols = df.select_dtypes(include=['object']).columns
            if len(categorical_cols) > 0:
                for col in categorical_cols[:2]:
                    series = df[col].dropna()
                    if series.empty:
                        continue
                    value_counts = series.value_counts()

                    # Detect high-cardinality columns and aggregate tail into 'Other'
                    unique_ratio = series.nunique() / len(series)
                    top_n = 10 if (unique_ratio > 0.3 or len(value_counts) > 12) else 15
                    value_counts = value_counts.sort_values(ascending=False)
                    others_sum = value_counts.iloc[top_n:].sum()
                    value_counts = value_counts.iloc[:top_n]
                    if others_sum > 0:
                        value_counts['××—×¨'] = others_sum

                    non_null_total = value_counts.sum()

                    plt.figure(figsize=(14, 8))
                    bars = plt.bar(range(len(value_counts)), value_counts.values,
                                 color=plt.cm.Set3(np.linspace(0, 1, len(value_counts))),
                                 alpha=0.8, edgecolor='black', linewidth=0.5)

                    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ Ğ½Ğ° ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹
                    for i, (bar, value) in enumerate(zip(bars, value_counts.values)):
                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01*max(value_counts.values),
                                f'{value}', ha='center', va='bottom', fontweight='bold', fontsize=10)

                    plt.title(f'×”×ª×¤×œ×’×•×ª {col}', fontsize=16, fontweight='bold', pad=20)
                    plt.xlabel(col, fontsize=12, fontweight='bold')
                    plt.ylabel('××¡×¤×¨', fontsize=12, fontweight='bold')
                    plt.xticks(range(len(value_counts)), value_counts.index, rotation=45, ha='right')
                    plt.grid(True, alpha=0.3, linestyle='--', axis='y')

                    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¿Ñ€Ğ¾Ñ†ĞµĞ½Ñ‚Ğ½Ñ‹Ğµ Ğ¼ĞµÑ‚ĞºĞ¸
                    for i, (bar, value) in enumerate(zip(bars, value_counts.values)):
                        percentage = (value / non_null_total) * 100 if non_null_total else 0
                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2,
                                f'{percentage:.1f}%', ha='center', va='center',
                                fontweight='bold', color='white', fontsize=9)

                    plt.tight_layout()
                    chart_path = os.path.join(temp_charts_dir, f'bar_chart_{col}.png')
                    plt.savefig(chart_path, dpi=300, bbox_inches='tight', facecolor='white')
                    plt.close()
                    chart_files.append(chart_path)

                    top3 = value_counts.head(3)
                    coverage = (top3.sum() / non_null_total) * 100 if non_null_total else 0
                    dom = ', '.join([f"{k} ({v/non_null_total*100:.1f}%)" for k, v in top3.items()])
                    chart_insights[chart_path] = f"{col}: ×§×˜×’×•×¨×™×•×ª ××•×‘×™×œ×•×ª â€” {dom}. ×›×™×¡×•×™ ×˜×•×¤â€‘3: {coverage:.1f}%"
                    chart_next_steps[chart_path] = (
                        "××” ×”×œ××”:\n"
                        "â€¢ × ×™×ª×•×— ×¢×•××§ ×œ×¤×™ ×§×˜×’×•×¨×™×•×ª ××•×‘×™×œ×•×ª\n"
                        "â€¢ ×”××¨×ª ×§×˜×’×•×¨×™×•×ª ×“×œ×•×ª × ×ª×•× ×™× ×œ-'××—×¨'\n"
                        "â€¢ ×‘×“×™×§×ª ×§×©×¨ ×œ×™×¢×“×™ ×”××¨×”/×”×›× ×¡×”"
                    )
            
            # ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸
            if chart_files:
                await update.message.reply_text(f"âœ… × ×•×¦×¨×• {len(chart_files)} ×ª×¨×©×™××™× ××§×¦×•×¢×™×™×!")
                
                # Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ¸Ñ€ÑƒĞµĞ¼ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¿Ğ¾ Ñ‚Ğ¸Ğ¿Ğ°Ğ¼ Ğ´Ğ»Ñ Ğ»ÑƒÑ‡ÑˆĞµĞ¹ Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
                chart_types = {
                    'histogram_box': 'ğŸ“Š ×”×™×¡×˜×•×’×¨××•×ª ×•-Box Plots',
                    'bar_chart': 'ğŸ“ˆ ×’×¨×¤×™× ×¢××•×“×•×ª',
                    'correlation_matrix': 'ğŸ”— ××˜×¨×™×¦×ª ×§×•×¨×œ×¦×™×”'
                }
                
                for i, chart_file in enumerate(chart_files):
                    try:
                        with open(chart_file, 'rb') as img_file:
                            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼ Ñ‚Ğ¸Ğ¿ Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ° Ğ¿Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ°
                            chart_type = "×ª×¨×©×™× ××§×¦×•×¢×™"
                            for key, value in chart_types.items():
                                if key in chart_file:
                                    chart_type = value
                                    break
                            
                            insight_text = chart_insights.get(chart_file, "")
                            caption = f"ğŸ“Š {chart_type}\n{insight_text}".strip()
                            if len(caption) > 900:
                                caption = caption[:900] + "â€¦"
                            await context.bot.send_photo(
                                chat_id=update.effective_chat.id,
                                photo=img_file,
                                caption=caption
                            )
                            next_steps = chart_next_steps.get(chart_file)
                            if next_steps:
                                await context.bot.send_message(chat_id=update.effective_chat.id, text=next_steps)
                    except Exception as e:
                        logger.error(f"Error sending chart {chart_file}: {e}")
                        await update.message.reply_text(f"âŒ ×©×’×™××” ×‘×©×œ×™×—×ª ×ª×¨×©×™× {i+1}")
                
                await update.message.reply_text(
                    "ğŸ‰ ×›×œ ×”×ª×¨×©×™××™× × ×©×œ×—×•!\n\n"
                    "ğŸ’¡ **×¡×•×’×™ ×”×ª×¨×©×™××™× ×©× ×•×¦×¨×•:**\n"
                    "â€¢ ğŸ“Š ×”×™×¡×˜×•×’×¨××•×ª ×¢× Box Plots\n"
                    "â€¢ ğŸ“ˆ ×’×¨×¤×™× ×¢××•×“×•×ª ×¢× ××—×•×–×™×\n"
                    "â€¢ ğŸ”— ××˜×¨×™×¦×ª ×§×•×¨×œ×¦×™×” ××ª×§×“××ª\n\n"
                    "**××” ×¢×›×©×™×•?**\n"
                    "ğŸ’¡ '×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª' - ×œ×§×‘×œ×ª ×ª×•×‘× ×•×ª ×¢×¡×§×™×•×ª\n"
                    "ğŸ“Š '×“×•×— PDF ××ª×§×“×' - ×œ×“×•×— ××§×¦×•×¢×™ ×¢× ×›×œ ×”×’×¨×¤×™×! ğŸ¯"
                )
            else:
                await update.message.reply_text("âŒ ×œ× × ×™×ª×Ÿ ×œ×™×¦×•×¨ ×ª×¨×©×™××™× ××”× ×ª×•× ×™× ×”× ×•×›×—×™×™×.")
            
        except Exception as e:
            logger.error(f"Error creating charts: {e}")
            await update.message.reply_text("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª×¨×©×™××™×")
        
        finally:
            # ĞÑ‡Ğ¸Ñ‰Ğ°ĞµĞ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹
            if 'temp_charts_dir' in locals():
                shutil.rmtree(temp_charts_dir, ignore_errors=True)
    
    async def handle_insights(self, update: Update, context: ContextTypes.DEFAULT_TYPE):
        """×˜×™×¤×•×œ ×‘×ª×•×‘× ×•×ª ×•×”××œ×¦×•×ª"""
        user_id = update.effective_user.id
        
        if not self.has_data(user_id):
            await update.message.reply_text(
                "âŒ ××™×Ÿ × ×ª×•× ×™× ×œ×ª×•×‘× ×•×ª!\n\n"
                "×× × ×©×œ×— ×œ×™ ×§×•×‘×¥ ×ª×—×™×œ×”."
            )
            return
        
        await update.message.reply_text("ğŸ’¡ ×× ×ª×— ×ª×•×‘× ×•×ª ×•××›×™×Ÿ ×”××œ×¦×•×ª...")
        
        try:
            df = self.user_data[user_id]['data']
            insights_text = "ğŸ’¡ **×ª×•×‘× ×•×ª ××ª×§×“××•×ª ×•×”××œ×¦×•×ª:**\n\n"
            
            # 1. ĞĞ½Ğ°Ğ»Ğ¸Ğ· ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¹
            numeric_cols = df.select_dtypes(include=[np.number]).columns
            if len(numeric_cols) > 1:
                insights_text += "**ğŸ”— × ×™×ª×•×— ×§×•×¨×œ×¦×™×•×ª:**\n"
                correlation_matrix = df[numeric_cols].corr()
                
                # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ Ñ‚Ğ¾Ğ¿-5 ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¹
                correlations = []
                for i in range(len(numeric_cols)):
                    for j in range(i+1, len(numeric_cols)):
                        col1, col2 = numeric_cols[i], numeric_cols[j]
                        corr_value = correlation_matrix.loc[col1, col2]
                        if not pd.isna(corr_value):
                            correlations.append((col1, col2, abs(corr_value)))
                
                # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ ÑĞ¸Ğ»Ğµ ĞºĞ¾Ñ€Ñ€ĞµĞ»ÑÑ†Ğ¸Ğ¸
                correlations.sort(key=lambda x: x[2], reverse=True)
                
                for i, (col1, col2, corr_abs) in enumerate(correlations[:5]):
                    corr_value = correlation_matrix.loc[col1, col2]
                    insights_text += f"â€¢ {col1} â†” {col2}: {corr_value:.3f}\n"
                
                insights_text += "\n"
            
            # 2. ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ²Ñ‹Ğ±Ñ€Ğ¾ÑĞ¾Ğ²
            if len(numeric_cols) > 0:
                insights_text += "**ğŸ” ×–×™×”×•×™ ×× ×•××œ×™×•×ª:**\n"
                for col in numeric_cols[:3]:
                    Q1 = df[col].quantile(0.25)
                    Q3 = df[col].quantile(0.75)
                    IQR = Q3 - Q1
                    lower_bound = Q1 - 1.5 * IQR
                    upper_bound = Q3 + 1.5 * IQR
                    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]
                    
                    if len(outliers) > 0:
                        outlier_percentage = (len(outliers) / len(df)) * 100
                        insights_text += f"â€¢ ×‘-{col}: × ××¦××• {len(outliers)} ×¢×¨×›×™× ×—×¨×™×’×™× ({outlier_percentage:.1f}%)\n"
                        insights_text += f"  - ×˜×•×•×— ×ª×§×™×Ÿ: {lower_bound:.2f} ×¢×“ {upper_bound:.2f}\n"
                        if outlier_percentage > 10:
                            insights_text += f"  - âš ï¸ ××—×•×– ×’×‘×•×” ×©×œ ×× ×•××œ×™×•×ª - ×™×™×ª×›×Ÿ ×©×™×™×“×¨×© ×˜×™×¤×•×œ\n"
                    else:
                        insights_text += f"â€¢ ×‘-{col}: ××™×Ÿ ×¢×¨×›×™× ×—×¨×™×’×™×\n"
                
                insights_text += "\n"
            
            # 3. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞµĞ½Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
            insights_text += "**ğŸ’¡ ×”××œ×¦×•×ª ×œ×©×™×¤×•×¨ ×”× ×ª×•× ×™×:**\n"
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ¿Ñ€Ğ¾Ğ¿ÑƒÑ‰ĞµĞ½Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ
            total_nulls = df.isnull().sum().sum()
            total_cells = len(df) * len(df.columns)
            if total_nulls > 0:
                null_percentage = (total_nulls / total_cells) * 100
                insights_text += f"â€¢ ×¢×¨×›×™× ×—×¡×¨×™×: {total_nulls:,} ({null_percentage:.1f}% ××”× ×ª×•× ×™×)\n"
                if null_percentage > 20:
                    insights_text += f"  - âš ï¸ ××—×•×– ×’×‘×•×” - ×‘×“×•×§ ××ª ××§×•×¨ ×”× ×ª×•× ×™×\n"
                elif null_percentage > 10:
                    insights_text += f"  - âš ï¸ ××—×•×– ×‘×™× ×•× ×™ - ×©×§×•×œ ×”×©×œ××” ×‘×××¦×¢×•×ª ×××•×¦×¢ ××• ×—×¦×™×•×Ÿ\n"
                else:
                    insights_text += f"  - âœ… ××—×•×– × ××•×š - × ×ª×•× ×™× ×‘××™×›×•×ª ×˜×•×‘×”\n"
            
            # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ½Ğ° Ğ´ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ‚Ñ‹
            duplicates = df.duplicated().sum()
            if duplicates > 0:
                duplicate_percentage = (duplicates / len(df)) * 100
                insights_text += f"â€¢ ×©×•×¨×•×ª ×›×¤×•×œ×•×ª: {duplicates:,} ({duplicate_percentage:.1f}%)\n"
                insights_text += f"  - ×”××œ×¦×”: ×”×¡×¨ ×›×¤×™×œ×•×™×•×ª ×œ×¤× ×™ ×”× ×™×ª×•×—\n"
            
            insights_text += "\n"
            
            # 4. Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¸Ğ½ÑĞ°Ğ¹Ñ‚Ñ‹
            insights_text += "**ğŸš€ ×ª×•×‘× ×•×ª ×¢×¡×§×™×•×ª:**\n"
            
            if len(numeric_cols) > 0:
                # ĞĞ°Ñ…Ğ¾Ğ´Ğ¸Ğ¼ ĞºĞ¾Ğ»Ğ¾Ğ½ĞºÑƒ Ñ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾Ğ¹ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒÑ
                max_var_col = numeric_cols[0]
                max_variance = df[max_var_col].var()
                for col in numeric_cols:
                    if df[col].var() > max_variance:
                        max_variance = df[col].var()
                        max_var_col = col
                
                insights_text += f"â€¢ ×”×¢××•×“×” {max_var_col} ××¨××” ××ª ×”×©×•× ×•×ª ×”×’×‘×•×”×” ×‘×™×•×ª×¨\n"
                insights_text += f"  - ×–×” ×¢×©×•×™ ×œ×”×¦×‘×™×¢ ×¢×œ ×”×–×“×× ×•×™×•×ª ××• ×¡×™×›×•× ×™× ×¢×¡×§×™×™×\n"
            
            # 5. Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ Ğ´Ğ°Ğ»ÑŒĞ½ĞµĞ¹ÑˆĞµĞ¼Ñƒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ñƒ
            insights_text += "\n**ğŸ¯ ×”××œ×¦×•×ª ×œ× ×™×ª×•×— × ×•×¡×£:**\n"
            if len(numeric_cols) > 1:
                insights_text += "â€¢ × ×™×ª×•×— ×¨×’×¨×¡×™×” ×œ×–×™×”×•×™ ×’×•×¨××™× ××©×¤×™×¢×™×\n"
                insights_text += "â€¢ × ×™×ª×•×— ××©×›×•×œ×•×ª (Clustering) ×œ×–×™×”×•×™ ×“×¤×•×¡×™×\n"
            if len(df.select_dtypes(include=['object']).columns) > 0:
                insights_text += "â€¢ × ×™×ª×•×— ANOVA ×œ×”×©×•×•××” ×‘×™×Ÿ ×§×‘×•×¦×•×ª\n"
                insights_text += "â€¢ × ×™×ª×•×— Chi-Square ×œ×‘×“×™×§×ª ×§×©×¨×™×\n"
            
            # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ğ¾Ğµ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ
            if len(insights_text) > 4000:
                parts = [insights_text[i:i+4000] for i in range(0, len(insights_text), 4000)]
                for i, part in enumerate(parts):
                    if i == 0:
                        await update.message.reply_text(part, parse_mode=ParseMode.MARKDOWN)
                    else:
                        await update.message.reply_text(f"ğŸ’¡ ×”××©×š ×”×ª×•×‘× ×•×ª (×—×œ×§ {i+1}):\n\n{part}", parse_mode=ParseMode.MARKDOWN)
            else:
                await update.message.reply_text(insights_text, parse_mode=ParseMode.MARKDOWN)
            
            await update.message.reply_text(
                "ğŸ¯ **×”×ª×•×‘× ×•×ª ×•×”×”××œ×¦×•×ª ×”×•×©×œ××•!**\n\n"
                "×¢×›×©×™×• ×™×© ×œ×š ×ª××•× ×” ××œ××” ×©×œ ×”× ×ª×•× ×™× ×©×œ×š.\n\n"
                "**××” ×¢×›×©×™×•?**\n"
                "ğŸ“Š '×“×•×— PDF ××ª×§×“×' - ×œ×§×‘×œ×ª ×“×•×— ××§×¦×•×¢×™ ×¢× ×›×œ ×”× ×™×ª×•×—×™× ×•×”×ª×•×‘× ×•×ª! ğŸš€\n\n"
                "×”×“×•×— ×”××ª×§×“× ×™×›×œ×•×œ ××ª ×›×œ ×”× ×™×ª×•×—×™×, ×”×ª×¨×©×™××™× ×•×”×ª×•×‘× ×•×ª ×‘××¡××š ××—×“ ××§×¦×•×¢×™ ×‘×¢×‘×¨×™×ª!",
                parse_mode=ParseMode.MARKDOWN
            )
            
        except Exception as e:
            logger.error(f"Error generating insights: {e}")
            await update.message.reply_text("âŒ ×©×’×™××” ×‘×™×¦×™×¨×ª ×”×ª×•×‘× ×•×ª")
    
    def run(self):
        """×”×¤×¢×œ×ª ×”×‘×•×˜"""
        logger.info("Starting Simple Hebrew Bot...")
        self.application.run_polling()

def main():
    """×”×¤×•× ×§×¦×™×” ×”×¨××©×™×ª"""
    
    # Get bot token from environment variable
    BOT_TOKEN = os.getenv("BOT_TOKEN")
    
    if not BOT_TOKEN:
        print("âŒ ERROR: BOT_TOKEN environment variable not set!")
        print("ğŸ“± Get your token from @BotFather in Telegram")
        print("ğŸ”§ Set the BOT_TOKEN environment variable:")
        print("   export BOT_TOKEN='your_bot_token_here'  # Linux/Mac")
        print("   $env:BOT_TOKEN='your_bot_token_here'    # Windows PowerShell")
        return
    
    try:
        print("Starting Simple Hebrew Bot with Advanced PDF Generation...")
        bot = SimpleHebrewBot(BOT_TOKEN)
        print("Bot created successfully!")
        print("Features available:")
        print("â€¢ Basic data analysis")
        print("â€¢ Professional charts generation")
        print("â€¢ Advanced insights and recommendations")
        print("â€¢ Regular PDF reports (old version)")
        print("â€¢ ADVANCED PDF reports with Hebrew RTL support (NEW!)")
        print("â€¢ Hebrew text display from right to left")
        print("â€¢ Professional charts in PDF")
        print("â€¢ Comprehensive data analysis")
        print("")
        print("Starting bot...")
        print("Now find the bot in Telegram and send /start")
        print("Upload CSV/Excel files and try the new '×“×•×— PDF ××ª×§×“×' button!")
        
        bot.run()
        
    except Exception as e:
        print(f"Error starting bot: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
